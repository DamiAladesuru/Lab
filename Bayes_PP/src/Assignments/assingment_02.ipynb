{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a49e4db",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eace3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c37210",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40503ed-20bb-4c74-b11a-e8efab67d530",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ecf6c7-4ec8-46d5-9008-a47d172d5b46",
   "metadata": {},
   "source": [
    "# Graded Assignment General Overview\n",
    "\n",
    "During the course, we will have three graded assignments. In this three assignment, you will go through the entire Probabilistic Programming (PP) workflow we cover in the course. In the first assignment, we will start with the first three steps of the workflow; assignment two will cover steps 4 and 5, and assignment three will cover step 6:\n",
    "\n",
    "|Assignment|Workflow Step|\n",
    "|---|---|\n",
    "|Assignment 1|1. Quantity to estiamte|\n",
    "|            |2. Scientific Modele|\n",
    "|            |3. Statistical Model|\n",
    "|Assignment 2|4. Synthetic Data|\n",
    "|            |5. Testing|\n",
    "|Assignment 3|6. Real data|\n",
    "\n",
    "\n",
    "__Background Paper__\n",
    "\n",
    "You will implement the workflow for a specific research project. We will use an existing paper as a basis (see table). While the paper is important for background information, in most parts, the assignment will be based on the preregistration that belongs to the paper. A preregistration is a document that outlines the research question, survey design, and estimation approach before the actual experiment is conducted. The data used in the paper is also publicly available, but there is no need to download it now; this will be done within the assignments.\n",
    "\n",
    "|Resource|Title|Link|\n",
    "|-----------|---------|---------|\n",
    "|Paper |Zachmann, L., McCallum, C., & Finger, R. (2023). Nudging farmers towards low‐pesticide practices: Evidence from a randomized experiment in viticulture. Journal of the Agricultural and Applied Economics Association, 2(3), 497-514.|[https://doi.org/10.1002/jaa2.76](https://doi.org/10.1002/jaa2.76) |\n",
    "|Preregistration|Zachmann, L., McCallum, C., & Finger, R. 'Uptake of fungi-resistant grapevines: The effect of personalized vs general risk exposure information'. Pre-registered on 01/12/2022, AsPredicted #84972.| [https://aspredicted.org/fb2c9.pdf](https://aspredicted.org/fb2c9.pdf) |\n",
    "|Open Data|Data on Swiss grapevine growers’ production, pest management and risk management decisions| [https://doi.org/10.3929/ethz-b-000568595](https://doi.org/10.3929/ethz-b-000568595) |\n",
    "\n",
    "__Aim of the Assignments__ \n",
    "\n",
    "The paper does not use a PP workflow but uses frequentist estimation methods. We will rebuild the entire research process using the PP workflow and estimate the quantities of interest using Bayesian methods. The paper conducts a survey with farmers to gather the data required for answering the research question. This could be similar to what you could do for your master's thesis. By working on the assignment, you practice how the PP workflow can be implemented for an actual research project. Additionally, it prepares you for applying it to your own research project.    \n",
    "\n",
    "*Heads up!* Be prepared that this will be quite a challenge and that for most of the questions there is not a single or clear-cut answer. Actually, an important learning outcome is that on the way to answering the research question, we need to make many (subjective) choices, and many alternative specifications or options would also be possible and justified. In terms of the grading, this means that the aim is not to find *one* correct answer (which does not exist) but rather to document and explain that you have thought about your choices and are aware of the implications.\n",
    "\n",
    "***\n",
    "\n",
    "# Assingment 2\n",
    "\n",
    "__Structure of assignement 2__\n",
    "\n",
    "1) Implement the statistical model in code \n",
    "\n",
    "2) Test the model inference using synthetic data\n",
    "\n",
    "3) Prepare output illustration that allow testing the hypothesis we aim to test\n",
    "\n",
    "\n",
    "*Good luck!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aabd49-288f-4284-9908-9fe6cc09092d",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "__Install and import packages__\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe7175-eb35-41c6-8c3c-fb91400fde00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packaged (only need to be done once after each restart of the jupyter server)\n",
    "#!pip install -q pandas matplotlib seaborn numpyro==0.15.2 jax==0.4.26 jaxlib==0.4.26 arviz networkx daft\n",
    "!pip install -q pandas matplotlib seaborn numpyro==0.15.2 jax jaxlib arviz networkx daft\n",
    "%conda install python-graphviz # install graphviz using conda (seems not to work with pip)\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=False) # clear all the output from conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db69516-a51f-4ef2-a71b-1fa7e60f36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "from ipywidgets import interactive\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from graphviz import Digraph\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import arviz as az\n",
    "import jax \n",
    "from jax import random\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "import numpyro.optim as optim\n",
    "from numpyro.infer import SVI, Trace_ELBO\n",
    "from numpyro.infer.autoguide import AutoLaplaceApproximation\n",
    "from numpyro.diagnostics import print_summary\n",
    "\n",
    "# Set seed for reproducibility\n",
    "rng_key = random.PRNGKey(1)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e31703-ee05-4a7a-b04c-53ff477099ef",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "__*Preparation*: Generate data to mirror the survey structure described in the preregistration__\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e532b7-4604-47b0-b8a6-f1b92b8cb8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data to mirror the data structure in Zachmann\n",
    "n = 294  # number of targeted in preregistration\n",
    "# Randomly assign treatment groups (g=0 control, g=1 personalized, g=2, general)\n",
    "G = np.random.randint(0,3,n) \n",
    "print('Number of farmers',n)\n",
    "print('G.shape',G.shape)\n",
    "\n",
    "# Plot the assignment to treatment\n",
    "plt.bar(*np.unique(G,return_counts=True));\n",
    "plt.ylabel('counts');\n",
    "plt.xticks([0,1,2], labels=['control','personalized','general']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c568342-fd11-4036-b50f-e95e63c1435a",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "__*Preparation*: Define the DAG and statistical model to have the same starting point__\n",
    "\n",
    "***\n",
    "\n",
    "Note: In order for everybody to have the same starting point for this second assignment, we all work with the same DAG and statistical model. In principle, you could continue with your model defined in the first assignment. However, that would make follow-up questions and grading difficult to align. The model provided below is very similar to the specification in the paper. However, this does not mean that this is the best or the only correct solution. In fact, there are multiple ways to improve the model. However, the model is relatively simple, making the following steps not too complicated. In general, it is a good strategy to start with a very simple model and go through the entire process; once this is running, we could stepwise make the model better. \n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba49e70-a39a-49f9-a473-5e2cf644bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a DGP as in assignment 01 \n",
    "dot = Digraph()\n",
    "\n",
    "# Observed notes\n",
    "dot.attr('node', style='filled', color='white') # Set color to white\n",
    "dot.node('Tper', 'Personal info')\n",
    "dot.node('Tgen', 'General info')\n",
    "dot.node('ES', 'Delta E[S]')\n",
    "dot.node('StdS', 'Delta Std[S]')\n",
    "\n",
    "dot.edges([('Tper','ES'),('Tgen','ES'),\n",
    "          ('Tper','StdS'),('Tgen','StdS')])\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c3a63d-87c0-4d60-9a8c-729d5de5f32e",
   "metadata": {},
   "source": [
    "__Based on the DAG define a complete data generating process (DGP), i.e. statistical model__ \n",
    "\n",
    "Let $G=0,1,2$ denote our three treatment groups, with $g=0$ being the control group, $g=1$ being the personalized info group, and $g=2$ being the generalized info group. Further, let $G[i]$ denote indexing the group of observation $i$. \n",
    "\n",
    "Define $Y_1$: Change in expected share of fungi-resistant grapevines (change before/after information treatment). The expectation is derived by asking for the most likely proportion, the minimum, and the maximum proportion. Then a triangular share distribution is used to approximate the expectation. \n",
    "\n",
    "*Model for $\\Delta E(S_i)$:*\n",
    "\n",
    "$Y_{1i} = \\Delta E(S_i) \\sim Normal(\\theta^{E}_{G[i]},\\sigma^{E})  $\n",
    "\n",
    "$\\theta^E_g \\sim Normal(0,0.3) $  for $g=0,1,2 $\n",
    "\n",
    "$\\sigma^{E} \\sim Exponential(3) $\n",
    "\n",
    "*Model for $\\Delta Std(S_i)$:*\n",
    "\n",
    "Define $Y_2$: Change in the standard deviation (std) of the intended share of fungi-resistant grapevines (change before/after information treatment). The std is also derived from the triangular share distribution. \n",
    "\n",
    "$Y_{2i} = \\Delta Std(S_i) \\sim Normal(\\theta^S_{G[i]},\\sigma^{Std})  $\n",
    "\n",
    "$\\theta^S_g \\sim Normal(0,0.3) $  for $g=0,1,2 $\n",
    "\n",
    "$\\sigma^{Std} \\sim Exponential(3) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2b334-d024-4c11-8f76-f169d65baeab",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Implement the statistical model in NumPyro code\n",
    "\n",
    "The next cell implements the statistical model in NumPyro code. Review the code and make sure you understand how it relates to the DGP defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4055132-db19-4450-a89a-8a83fe79819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelDiff(G, DiffEI=None,DiffStdI=None):\n",
    "    # Model for Diff EI\n",
    "    mu_DiffEI = numpyro.sample('mu_DiffEI', dist.Normal(0,0.3).expand([3]))\n",
    "    sigma_DiffEI = numpyro.sample('sigma_DiffEI', dist.Exponential(3))\n",
    "    DiffEI = numpyro.sample('DiffEI', dist.Normal(mu_DiffEI[G],sigma_DiffEI), obs=DiffEI)\n",
    "\n",
    "    # Model of Diff StdI\n",
    "    mu_DiffStdI = numpyro.sample('mu_DiffStdI', dist.Normal(0,0.3).expand([3]))\n",
    "    sigma_DiffStdI = numpyro.sample('sigma_DiffStdI', dist.Exponential(3))\n",
    "    DiffStdI = numpyro.sample('DiffStdI', dist.Normal(loc=mu_DiffStdI[G], scale=sigma_DiffStdI), obs=DiffStdI)\n",
    "    \n",
    "# Sample from prior\n",
    "rng_key, rng_key_ = random.split(rng_key)\n",
    "prior_predictive = Predictive(modelDiff, num_samples=100)\n",
    "prior_samples = prior_predictive(rng_key_,G=G)\n",
    "\n",
    "print('Elements in \"prior_predictive\"', prior_samples.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f87cc-b5ba-4c74-90b4-17e69a0d73fc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99137bc77444a9060d6341721f0afa6c",
     "grade": true,
     "grade_id": "cell-db59946935bf8645",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "***\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "__*Task 1*: Implement the statistical model in NumPyro code__ (6 points)\n",
    "\n",
    "</div>\n",
    "a) Use the cell below to print the shape of all the elements in the dictionary \"prior_predictive\" (3 points)\n",
    "\n",
    "*For a): Implement you answer using the cell below*\n",
    "\n",
    "b) Explain in your own words, for every element in the dictionary \"prior_predictive\"  why it has the respective shape, i.e., define verbally the dimension of each variable. (3 points)\n",
    "\n",
    "For example, assume a ```a.shape = (3,4)``. You should say what the 3 and the 4 mean. \n",
    "\n",
    "*For b): Add your answer here:*\n",
    "\n",
    "YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca59473-d868-4c7a-ae24-7750076b0472",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f97c7c70b76b6111ffe3b7a035c6264a",
     "grade": true,
     "grade_id": "cell-34d74dfa0fa6cfab",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1a) Print shape of keys\n",
    "print('Shape of elements in \"prior_predictive\"', prior_samples.shape)\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ca098-d77f-49d1-9f04-0a7de6a9c507",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78c9a7e6b9f83bcbe13acb5c24e88799",
     "grade": true,
     "grade_id": "cell-a575f38a5c92eead",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "***\n",
    "## Prior predictive check\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "__*Task 2)*: Prior predictive check__ (8 Points)\n",
    "</div>\n",
    "\n",
    "Generally, we would need to check all the priors used in the model. For this task, we restrict ourselves to checking only one prior. \n",
    "\n",
    "Above we use a prior distribution: \n",
    "\n",
    "$\\sigma^{E} \\sim Exponential(3) $ \n",
    "\n",
    "consider as an alternative prior: \n",
    "\n",
    "$\\sigma^{E} \\sim Exponential(1) $ \n",
    "\n",
    "\n",
    "2a) Use the cell below to implement this different prior (all else remains the same). (4 Points)\n",
    "\n",
    "*For a): Implement your answer using the cell below*\n",
    "\n",
    "b) Use the cell after the next to plot the prior distribution from these two models. Discuss which specification you find more appropriate and motivate why you think so. (4 Points)\n",
    "\n",
    "*For b): Add your answer here:*\n",
    "\n",
    "YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7b6203-1c66-4ee4-bf41-8889394c1e53",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bd5695afcb463259e0c8752e8329225",
     "grade": true,
     "grade_id": "cell-fe78fccc9a51c998",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Use this cell to answer Task 2a)\n",
    "def modelDiff_altPrior(G, DiffEI=None,DiffStdI=None):\n",
    "    # Model for Diff EI\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Model of Diff StdI\n",
    "    mu_DiffStdI = numpyro.sample('mu_DiffStdI', dist.Normal(0,0.3).expand([3]))\n",
    "    sigma_DiffStdI = numpyro.sample('sigma_DiffStdI', dist.Exponential(3)) # 2 Points\n",
    "    DiffStdI = numpyro.sample('DiffStdI', dist.Normal(loc=mu_DiffStdI[G], scale=sigma_DiffStdI), obs=DiffStdI)\n",
    "    \n",
    "# Sample from prior\n",
    "rng_key, rng_key_ = random.split(rng_key)\n",
    "prior_predictive_altPrior = Predictive(modelDiff_altPrior, num_samples=100)\n",
    "prior_samples_altPrior = prior_predictive_altPrior(rng_key_,G=G)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf2767-916b-4423-9e48-ce18cefae9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to plot prior samples from the two different model specifications\n",
    "# Sample from orginal specification \n",
    "rng_key, rng_key_ = random.split(rng_key)\n",
    "prior_predictive = Predictive(modelDiff, num_samples=100)\n",
    "prior_samples = prior_predictive(rng_key_,G=G)\n",
    "\n",
    "# Sample from alternative prior specification\n",
    "rng_key, rng_key_ = random.split(rng_key)\n",
    "prior_predictive_altPrior = Predictive(modelDiff_altPrior, num_samples=100)\n",
    "prior_samples_altPrior = prior_predictive_altPrior(rng_key_,G=G)    \n",
    "\n",
    "def plot_hist_G(outcome,G,xlabel='x',ref=None,ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig,ax = plt.subplots(figsize=(4,4))\n",
    "    ax.hist(outcome[:,G==0].flatten(),alpha=0.5,label=\"control\",bins=50);\n",
    "    ax.hist(outcome[:,G==1].flatten(),alpha=0.5,label=\"pers.\",bins=50);\n",
    "    ax.hist(outcome[:,G==2].flatten(),alpha=0.5,label=\"gen.\",bins=50);\n",
    "    if title is None:\n",
    "        ax.set_title('Difference');\n",
    "    else:\n",
    "        ax.set_title(title);\n",
    "        \n",
    "    ax.set_xlabel(rf'$\\Delta$ {xlabel}');\n",
    "    ax.legend(frameon=False)\n",
    "\n",
    "    if ref is not None:\n",
    "        ax.axvline(ref[0],ls='--', color = 'black',)\n",
    "        ax.axvline(ref[1],ls='--', color = 'black',)\n",
    "        ax.axvline(ref[2],ls='--', color = 'black',)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, tight_layout=True,figsize=(8,4))\n",
    "\n",
    "plot_hist_G(prior_samples['DiffEI'],G,xlabel='DiffEI',ax=ax1,title='Orignal Prior')\n",
    "plot_hist_G(prior_samples_altPrior['DiffEI'],G,xlabel='DiffEI',ax=ax2, title='Alternative Prior')\n",
    "\n",
    "# Note that this restrict the x-axis that is shown to the most relevant range, you might want to comment this out to see the entire distributions\n",
    "ax1.set_xlim(-3,3);\n",
    "ax2.set_xlim(-3,3);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5db68-7ca9-4ab2-affe-f8297db18d1b",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Test Model with synthetic data\n",
    "\n",
    "In a assingment 1 we specified the hypothesis we aim to test. To have the same starting point, assume we would want to test the following hypothesis:\n",
    "\n",
    "__H1__: Information change intentions, and personalized information on fungicide risk exposure is more important than more general information to change intentions (here, land devoted to fungi-resistant grapes).\n",
    "\n",
    "We can test the hypothesis by comparing if $\\theta^E_1>\\theta^E_0$ and $\\theta^E_2>\\theta^E_0$, i.e. information changes intentions. And $\\theta^E_1>\\theta^E_2$. i.e. personalized information is more important than more general information.\n",
    "\n",
    "__H2__: Because personalized information is more relevant for the farmer, personalized information __reduces__ the uncertainty of the intention more then general information.\n",
    "\n",
    "We can test the hypothesis by comparing if $\\theta^S_1<\\theta^S_0$, i.e., information reduces uncertainty compared to the control group, and $\\theta^S_1<\\theta^S_2$, i.e., personalized information leads to a larger reduction in the uncertainty then generalized information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5778ca-4cc3-4519-ae02-fee698be86c9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "048e5bb630118281c828528d2cb32ecf",
     "grade": true,
     "grade_id": "cell-1ce8d8ff775ca9a6",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "***\n",
    "__Condition the model to create a synthetic dataset__\n",
    "\n",
    "The cell below can be used to condition the coefficient of the model to specific values. We can then use these conditioned model to generate synthetic data where we know exactly\n",
    "the \"true\" coefficients. Consider how we did this in examples in the lecture.\n",
    "    \n",
    "Using the cell below, we want to generate synthetic data for which all our assumed hypotheses above are true. The general idea is that we then use this synthetic data in our inference step to test whether we can test our hypothesis in a setting where we know that it is true. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "__*Task 3)*: Condition the model to create a synthetic dataset__ (10 Points)\n",
    "</div>\n",
    "\n",
    "2a) Use the cell below to condition the model on parameter values that would exactly match the hypothesis we defined above. (4 Points)\n",
    "\n",
    "*For a): Implement your answer using the cell below*\n",
    "\n",
    "b) Motivate and explain your chosen values for each of the six coefficients. Explain how you interpret each of the six coefficients verbally. (6 Points)\n",
    "\n",
    "*For b): Add your answer here:*\n",
    "\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f6d1c-1905-46d2-af29-67aedb88c405",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89a06c021f921f0a3e09eac2e2024c95",
     "grade": true,
     "grade_id": "cell-05fb2887eef1b2af",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Use this cell to answer 4a)\n",
    "\n",
    "# Condition the model \n",
    "coefTrue = {\n",
    "            # YOUR CODE HERE\n",
    "            # 'mu_DiffEI': ... , \n",
    "            # 'mu_DiffStdI': ... ,\n",
    "            'sigma_DiffEI':np.array([0.01]),\n",
    "            'sigma_DiffStdI':np.array([0.01]),\n",
    "           }\n",
    "# Use coefTrue to condition the model\n",
    "condition_model = numpyro.handlers.condition(modelDiff, data=coefTrue)\n",
    "# Generate synthetic data using conditioned model\n",
    "conditioned_predictive = Predictive(condition_model, num_samples=1)\n",
    "condition_samples = conditioned_predictive(rng_key_,G=G)\n",
    "condition_samples\n",
    "\n",
    "# Plot the generated data\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, tight_layout=True,figsize=(8,4))\n",
    "plot_hist_G(condition_samples['DiffEI'],G,xlabel='DiffEI',ref=condition_samples['mu_DiffEI'][0],ax=ax1, title='')\n",
    "plot_hist_G(condition_samples['DiffStdI'],G,xlabel='DiffStdI',ref=condition_samples['mu_DiffStdI'][0],ax=ax2, title='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f26cf0-5b12-492e-bf61-ad6f81d16bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the conditioned data to define the outcome variables \n",
    "DiffEI = condition_samples['DiffEI'][0]\n",
    "DiffStdI = condition_samples['DiffStdI'][0]\n",
    "print('DiffEI.shape',DiffEI.shape)\n",
    "print('DiffStdI.shape',DiffStdI.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106cb119-5b7c-4023-866f-caa040b29928",
   "metadata": {},
   "source": [
    "## Run the model backward (inference), using the conditioned data\n",
    "\n",
    "The next cell shows the inference step using quadratic approximation (in the commented-out part), which we have used multiple times in class. However, here we use MCMC, even though we have not covered it in class. This is also what you might want to do in an actual application. The next cell gives code for quadratic approximation and for MCMC. For the following, you can basically ignore how we perform inference here. The crucial point is that in base cases, we obtain samples from the posterior; how we get those samples does not really matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab068b-6f6f-456a-b715-632bc9580e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guide = AutoLaplaceApproximation(modelDiff)\n",
    "#svi = SVI(modelDiff,guide,optim.Adam(0.1),Trace_ELBO(),\n",
    "#    G=G,DiffEI=DiffEI,DiffStdI=DiffStdI\n",
    "#)\n",
    "#svi_result = svi.run(random.PRNGKey(0), 2000)\n",
    "#params = svi_result.params\n",
    "#post_samples = guide.sample_posterior(random.PRNGKey(1), params, sample_shape=(1000,))\n",
    "#print_summary(post_samples, 0.89, False)\n",
    "\n",
    "\n",
    "# Note: For an actual application we would rather use MCMC, the following line would achive this \n",
    "rng_key, rng_key_ = random.split(rng_key)\n",
    "kernel = NUTS(modelDiff)\n",
    "mcmc = MCMC(kernel, num_samples=1000, num_warmup=1000, num_chains=1)\n",
    "mcmc.run(rng_key_,G=G,DiffEI=DiffEI,DiffStdI=DiffStdI)\n",
    "azMCMC = az.from_numpyro(mcmc)\n",
    "post_samples = mcmc.get_samples()\n",
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b40cf8-ad86-41ce-9368-5b934282cd0f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "409f79a943b9d52e9463c8911195d416",
     "grade": true,
     "grade_id": "cell-5a72a70feb3e5866",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "***\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "__*Task 4*: Inspect dimensions of posterior samples__ (5 Points)\n",
    "</div>\n",
    "\n",
    "2a) Use the cell below to print the shape of all the elements in the dictionary ```post_samples```.  (2 Points)\n",
    "\n",
    "*For a): Implement your answer using the cell below*\n",
    "\n",
    "b) Explain in your own words, for every element in the dictionary ```post_samples```  why it has the respective shape, i.e., define verbally the dimension of each variable. (2 Points)\n",
    "\n",
    "For example assume a ```a.shape = (3,4)``` you should say what the 3 and the 4 mean. \n",
    "\n",
    "*For b): Add your answer here:*\n",
    "\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "c) Explain in your own words why ```post_samples``` does not include ```DiffEI``` and ```DiffStdI```, as it was the case for ```prior_samples``` above. (1 Point)\n",
    "\n",
    "YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad21151-ead5-4c94-a234-c80ee2f35d8d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "796c1a1701ca02c59e33bd04f073eb0a",
     "grade": true,
     "grade_id": "cell-7143e489df470327",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Add your solution to 4a)\n",
    "# Print the shape of elements\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84fe81-d6b1-4391-bac1-6e186ff67162",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a3ccb44f3750c40658159d481e3ad79",
     "grade": true,
     "grade_id": "cell-64ab2f6994724e38",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444cae5-7d71-4bdf-b650-e87e426bc3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(azMCMC,var_names=['mu_DiffEI']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446a3c7-9dce-4d46-acd0-3023344a1a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(azMCMC,var_names=['mu_DiffStdI']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f97e5-0a3a-42c6-8bf8-17ab474f17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(azMCMC,var_names=['sigma_DiffEI']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff627093-a557-4301-9cb5-913e708bed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(azMCMC,var_names=['sigma_DiffStdI']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3cfa2-a9bc-4347-9da6-f8b76cf71c87",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "888fdffdad2a0aefc386d700f7b375e7",
     "grade": true,
     "grade_id": "cell-3a9bb9babd15ff6f",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "***\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "__*Task 5*: Check if inference worked__ (3 Points)\n",
    "\n",
    "Discuss how you could check if inference has worked. Based on the results and plots above list clearly three aspects you would consider to check if inference has worked. \n",
    "</div>\n",
    "\n",
    "YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b77e9-b978-43d0-9018-b87ac8b324a7",
   "metadata": {},
   "source": [
    "# Prepare outputs to test hypothesis \n",
    "\n",
    "The following plots are useful to use the posterior samples to test (some of) our hypotheses. Note that this is still based on the synthetic data where we know what the true values are. So they cannot actually be used to test our hypothesis. But we can check, using data for which we know that our hypotheses are true, how we could prepare plots to test the hypothesis. The idea is that once we work with the actual data we will use exactly the same types of plots.  \n",
    "\n",
    "Note that the plots below are intentionally without axis descriptions, it is part of the task to figure this out. Of course, for an actual application, we would add meaningful axis descriptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99978d-ba71-4904-b546-f7d51942dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, tight_layout=True,figsize=(8,4))\n",
    "# Consider this plot for 6a)\n",
    "ax1.hist((post_samples['mu_DiffEI'][:,1]-post_samples['mu_DiffEI'][:,2]),bins=50);\n",
    "ax1.set_title('Plot for task 6a')\n",
    "ax1.set_xlabel('x-label')\n",
    "ax1.set_ylabel('y-label')\n",
    "\n",
    "# Consider this plot for 6b)\n",
    "ax2.hist((post_samples['mu_DiffStdI'][:,1]-post_samples['mu_DiffStdI'][:,0]),bins=50);\n",
    "ax2.set_title('Plot for task 6b')\n",
    "ax2.set_xlabel('x-label')\n",
    "ax2.set_ylabel('y-label')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99fe046-3890-4332-bc11-0e1eb40cac34",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f20fd889d33e8bf9745aa7939a99d08",
     "grade": true,
     "grade_id": "cell-12e6a2e82bff7866",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "***\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "__*Task 6*: Interpret outputs to test hypothesis__ (6 Points)\n",
    "\n",
    "</div>\n",
    "\n",
    "6a) Try to understand what the left plot is showing. (3 points)\n",
    "\n",
    "- Describe in words what the plot shows\n",
    "\n",
    "- Discuss which parts of the hypothesis you could test with this plot. To make your answer precise, use the mathematical notation used above to define the hypothesis.\n",
    "\n",
    "- Describe how you would use the plot to test this part of the hypothesis \n",
    "\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "6b) Try to understand what the right plot is showing. (3 points)\n",
    "\n",
    "- Describe in words what the plot shows\n",
    "\n",
    "- Discuss which parts of the hypothesis you could test with this plot. To make your answer precise, use the mathematical notation used above to define the hypothesis.\n",
    "\n",
    "- Describe how you would use the plot to test this part of the hypothesis \n",
    "\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4dbed9-da2b-4332-b28e-0e1fa86ae0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
